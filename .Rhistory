cnmf <- reticulate::import('cnmf')
sc <- reticulate::import('scanpy')
num_iterations <- as.integer(num_iterations)
num_workers    <- as.integer(num_workers)
num_hvgenes    <- as.integer(num_hvgenes)
n_components <- as.integer(n_components)
seed <- as.integer(seed)
density_threshold <- as.double(density_threshold)
message('--- Writing intermediate AnnData ---')
data.h5ad <- sc$AnnData(X = t(assay(sce, assay)))
file_name <- paste0('data/', file_name)
sc$write(file_name,   data.h5ad)
message('--- Performing cNMF ---')
# initializing the cNMF object
cnmf_obj = cnmf$cNMF(output_dir = output_dir,
name = run_name)
# pre-processing the data to retain only the number of over-dispersed genes
# that we want
cnmf_obj$prepare(counts_fn = file_name,
components = levels,
n_iter = num_iterations,
seed = seed,
num_highvar_genes = num_hvgenes)
# performing parallel cNMF
reticulate::py_suppress_warnings( #suppressing warnings
cnmf_obj$factorize_multi_process(total_workers = num_workers))
# defining the consensus
cnmf_obj$combine()
# Stability vs Loss
cnmf_obj$k_selection_plot(close_fig=FALSE)
cnmf_obj$paths['k_selection_plot']
# Coherence of the decomposition level
sapply(levels, function(level_i){ # which decomposition level we want to look at
cnmf_obj$consensus(k = level_i,
density_threshold = density_threshold,
show_clustering = TRUE,
close_clustergram_fig = TRUE)
})
# cnmf.model data fieldsâ€¦
# 1 : usage_norm
# 2 : gep_scores
# 3 : gep_tpm
# 4 : topgenes
cnmf.model <- cnmf_obj$load_results(K = n_components,
density_threshold = density_threshold)
message('--- Storing Results ---')
patterns_names <- paste0(rep('NNF_', n_components), seq_len(n_components))
# Cell view
cnmf_h.dgCMatrix <- as(cnmf.model[[1]], 'sparseMatrix')
colnames(cnmf_h.dgCMatrix) <- patterns_names
rownames(cnmf_h.dgCMatrix) <- colnames(sce)
result_name <- change_default_name(result_name, reducedDimNames(sce))
reducedDims(sce)[[result_name]] <- cnmf_h.dgCMatrix
# Gene view
cnmf_w.dgCMatrix <- as(cnmf.model[[2]], 'sparseMatrix')
colnames(cnmf_w.dgCMatrix) <- patterns_names
rownames(cnmf_w.dgCMatrix) <- rownames(sce)
metadata(sce)[[result_name]] <- cnmf_w.dgCMatrix
if(!return_model) return(sce)
return(list(obj = sce, model = cnmf.model))
}
decomp_cnmf(sce)
is_package_installed('ParetoTI')
n_dimensions
n_dimensions=14
# ParetoTI
method.chr = 'pcha'
normalise_var.bool = TRUE
verbose.bool = FALSE
## Selecting the optimal number of prototypes / latents via bootstrap
n_pcs.int                = as.integer(50)
max_k.int                = as.integer(16)    # maximum k number
maxiter.int              = as.integer(50)  # maximum number of iterations to find the archetypes in a given run
bootstrap.bool           = TRUE              # whether to perform bootstrap for more robust results
boostrap_number.int      = as.integer(10)    # number of trial via bootstrap
parallel_type.chr        = 'm'               # to run locally or on a single node
volume_ratio.chr         = 't_ratio'         # use none for quicker and less precise computations
delta.int                = as.integer(0)     #
conv_crit.double         = as.double(1e-04)  # convergence threshold
order_type.chr           = "align"           #
sample_proportion.double = NULL  # as.double(0.25) | with NULL it runs multiple times on the whole data set, to evaluate local optima.
is_package_installed('ParetoTI')
load('data/sce.rda') #sce
decomp_name = 'pca'
n_dimensions=14
# ParetoTI
method.chr = 'pcha'
normalise_var.bool = TRUE
verbose.bool = FALSE
## Selecting the optimal number of prototypes / latents via bootstrap
n_pcs.int                = as.integer(50)
max_k.int                = as.integer(16)    # maximum k number
maxiter.int              = as.integer(50)  # maximum number of iterations to find the archetypes in a given run
bootstrap.bool           = TRUE              # whether to perform bootstrap for more robust results
boostrap_number.int      = as.integer(10)    # number of trial via bootstrap
parallel_type.chr        = 'm'               # to run locally or on a single node
volume_ratio.chr         = 't_ratio'         # use none for quicker and less precise computations
delta.int                = as.integer(0)     #
conv_crit.double         = as.double(1e-04)  # convergence threshold
order_type.chr           = "align"           #
sample_proportion.double = NULL  # as.double(0.25) | with NULL it runs multiple times on the whole data set, to evaluate local optima.
n_pcs=50                # number of dimensions
max_k=16                # maximum k number
maxiter=50              # maximum number of iterations to find the archetypes in a given run
boostrap_number=10      #
delta=0                 #
conv_crit=1e-04         #
seed=42                 #
bootstrap=TRUE          # whether to perform bootstrap for more robust results
parallel_type='m'       # to run locally or on a single node
volume_ratio='t_ratio'  # use none for quicker and less precise computations
order_type="align"      #
sample_proportion=NULL  # as.double(0.25) | with NULL it runs multiple times on the whole data set, to evaluate local optima.
message('--- Checking packages ---')
is_package_installed('ParetoTI')
bootstrap            = TRUE              # whether to perform bootstrap for more robust results
parallel_type        = 'm'               # to run locally or on a single node
volume_ratio         = 't_ratio'         # use none for quicker and less precise computations
compressed_representation
interval_of_k
# setting the range of archetypes to test on the data
if(is.null(interval_of_k)) interval_of_k <- seq(2, max_k)
n_pcs=50                # number of dimensions
max_k=16                # maximum k number
maxiter=50              # maximum number of iterations to find the archetypes in a given run
boostrap_number=10      #
delta=0                 #
conv_crit=1e-04         #
seed=42                 #
bootstrap=TRUE          # whether to perform bootstrap for more robust results
parallel_type='m'       # to run locally or on a single node
volume_ratio='t_ratio'  # use none for quicker and less precise computations
order_type="align"      #
sample_proportion=NULL  # as.double(0.25) | with NULL it runs multiple times on the whole data set, to evaluate local optima.
# setting the range of archetypes to test on the data
if(is.null(interval_of_k)) interval_of_k <- seq(2, max_k)
interval_of_k
seq(2, max_k)
interval_of_k=NULL
# setting the range of archetypes to test on the data
if(is.null(interval_of_k)) interval_of_k <- seq(2, max_k)
interval_of_k
bootstrap
boostrap_number
maxiter
parallel_type
seed
volume_ratio
delta
conv_crit
order_type
sample_proportion
compressed_representation=NULL
sce
n_dimensions=50         # number of dimensions for the compressed representation
compression_method
compression_method='pca'# dimensionality reduction method
assay='logcounts'       # assay to be reduced in dimensions
sce
n_dimensions
assay
# Setting the compressed representation
compressed_representation <- switch(compression_method,
'pca' = decomp_pca(sce,
n_dimensions,
assay = assay),
'nmf' = decomp_nmf(sce,
n_dimensions,
assay = assay),
'none' = assay(sce, assay))
source("~/Documents/ruler/R/decomp_pca.R", echo=TRUE)
source("~/Documents/ruler/R/decomp_nmf.R", echo=TRUE)
# Setting the compressed representation
compressed_representation <- switch(compression_method,
'pca' = decomp_pca(sce,
n_dimensions,
assay = assay),
'nmf' = decomp_nmf(sce,
n_dimensions,
assay = assay),
'none' = assay(sce, assay))
sce
assay='counts'       # assay to be reduced in dimensions
# Setting the compressed representation
compressed_representation <- switch(compression_method,
'pca' = decomp_pca(sce,
n_dimensions,
assay = assay),
'nmf' = decomp_nmf(sce,
n_dimensions,
assay = assay),
'none' = assay(sce, assay))
source("~/Documents/ruler/R/center_and_scale.R", echo=TRUE)
# Setting the compressed representation
compressed_representation <- switch(compression_method,
'pca' = decomp_pca(sce,
n_dimensions,
assay = assay),
'nmf' = decomp_nmf(sce,
n_dimensions,
assay = assay),
'none' = assay(sce, assay))
compressed_representation
sce <- switch(compression_method,
'pca' = decomp_pca(sce,
n_dimensions,
assay = assay),
'nmf' = decomp_nmf(sce,
n_dimensions,
assay = assay),
'none' = assay(sce, assay))
sce
assay(sce, assay)
interval_of_k
if(reduction_method == 'none'){
reduced_matrix <- assay(sce, assay)
}else{
reduced_matrix <- reducedDim(sce)[[reduction_method]]}
reduction_method='pca'# dimensionality reduction method
if(reduction_method == 'none'){
reduced_matrix <- assay(sce, assay)
}else{
reduced_matrix <- reducedDim(sce)[[reduction_method]]}
reducedDim(sce)
reducedDim(sce)[[reduction_method]]
reducedDimNames(sce)
reducedDim(sce)
names(reducedDim(sce))
sce
sce
names(reducedDim(sce))
reducedDim(sce)['pca']
reducedDim(sce)[['pca']]
sce
reducedDim(sce)
## ADD ALSO ICA!
sce <- switch(reduction_method,
'pca' = decomp_pca(sce,
n_dimensions,
assay = assay,
result_name = reduction_method),
'nmf' = decomp_nmf(sce,
n_dimensions,
assay = assay,
result_name = reduction_method),
'none' = sce)
if(reduction_method == 'none'){
reduced_matrix <- assay(sce, assay)
}else{
reduced_matrix <- reducedDim(sce)[[reduction_method]]}
reduction_method
sce
reducedDim(sce)
names(reducedDim(sce))
names(reducedDimNames(sce))
reducedDimNames(sce)
reducedDimNames(sce)[['pca']]
reducedDimNames(sce)['pca']
sce
source("~/Documents/ruler/R/decomp_pca.R", echo=TRUE)
## ADD ALSO ICA!
sce <- switch(reduction_method,
'pca' = decomp_pca(sce,
n_dimensions,
assay = assay,
result_name = reduction_method),
'nmf' = decomp_nmf(sce,
n_dimensions,
assay = assay,
result_name = reduction_method),
'none' = sce)
source("~/Documents/ruler/R/decomp_pca.R", echo=TRUE)
## ADD ALSO ICA!
sce <- switch(reduction_method,
'pca' = decomp_pca(sce,
n_dimensions,
assay = assay,
result_name = reduction_method),
'nmf' = decomp_nmf(sce,
n_dimensions,
assay = assay,
result_name = reduction_method),
'none' = sce)
source("~/Documents/ruler/R/decomp_pca.R", echo=TRUE)
## ADD ALSO ICA!
sce <- switch(reduction_method,
'pca' = decomp_pca(sce,
n_dimensions,
assay = assay,
result_name = reduction_method),
'nmf' = decomp_nmf(sce,
n_dimensions,
assay = assay,
result_name = reduction_method),
'none' = sce)
sce
names(reducedDims(sce))
if(reduction_method == 'none'){
reduced_matrix <- assay(sce, assay)
}else{
reduced_matrix <- reducedDims(sce)[[reduction_method]]}
reduced_matrix
reduced_matrix
interval_of_k
aas.model = ParetoTI::k_fit_pch(data            = reduced_matrix,
ks              = interval_of_k,
check_installed = TRUE,
bootstrap       = bootstrap,
bootstrap_N     = boostrap_number,
maxiter         = maxiter,
bootstrap_type  = parallel_type,
seed            = seed,
volume_ratio    = volume_ratio,
delta           = delta,
conv_crit       = conv_crit,
order_type      = order_type,
sample_prop     = sample_proportion)
is_package_installed('reticulate')
reticulate::virtualenv_python()
reticulate::virtualenv_list()
reticulate::use_virtualenv('reticulate_PCHA')
reticulate::use_virtualenv('reticulate_PCHA')
reticulate::use_virtualenv('reticulate_PCHA')
n_dimensions         = as.integer(n_dimensions)           # number of components
max_k                = as.integer(max_k)           # maximum k number
maxiter              = as.integer(maxiter)         # maximum number of iterations to find the archetypes in a given run
boostrap_number      = as.integer(boostrap_number) # number of trial via bootstrap
delta                = as.integer(delta)
conv_crit            = as.double(conv_crit)        # convergence threshold
seed                 = as.integer(seed)
# setting the range of archetypes to test on the data
if(is.null(interval_of_k)) interval_of_k <- seq(2, max_k)
## ADD ALSO ICA!
sce <- switch(reduction_method,
'pca' = decomp_pca(sce,
n_dimensions,
assay = assay,
result_name = reduction_method),
'nmf' = decomp_nmf(sce,
n_dimensions,
assay = assay,
result_name = reduction_method),
'none' = sce)
if(reduction_method == 'none'){
reduced_matrix <- assay(sce, assay)
}else{
# we need to transpose the matrix to have it features x cells
reduced_matrix <- t(reducedDims(sce)[[reduction_method]])}
aas.model = ParetoTI::k_fit_pch(data            = reduced_matrix,
ks              = interval_of_k,
check_installed = TRUE,
bootstrap       = bootstrap,
bootstrap_N     = boostrap_number,
maxiter         = maxiter,
bootstrap_type  = parallel_type,
seed            = seed,
volume_ratio    = volume_ratio,
delta           = delta,
conv_crit       = conv_crit,
order_type      = order_type,
sample_prop     = sample_proportion)
reticulate::use_virtualenv('reticulate_PCHA')
aas.model = ParetoTI::k_fit_pch(data            = reduced_matrix,
ks              = interval_of_k,
check_installed = TRUE,
bootstrap       = bootstrap,
bootstrap_N     = boostrap_number,
maxiter         = maxiter,
bootstrap_type  = parallel_type,
seed            = seed,
volume_ratio    = volume_ratio,
delta           = delta,
conv_crit       = conv_crit,
order_type      = order_type,
sample_prop     = sample_proportion)
reticulate::use_virtualenv('reticulate_PCHA')
aas.model = ParetoTI::k_fit_pch(data            = reduced_matrix,
ks              = interval_of_k,
check_installed = TRUE,
bootstrap       = bootstrap,
bootstrap_N     = boostrap_number,
maxiter         = maxiter,
bootstrap_type  = parallel_type,
seed            = seed,
volume_ratio    = volume_ratio,
delta           = delta,
conv_crit       = conv_crit,
order_type      = order_type,
sample_prop     = sample_proportion)
.rs.restartR()
reticulate::use_virtualenv('reticulate_PCHA')
aas.model = ParetoTI::k_fit_pch(data            = reduced_matrix,
ks              = interval_of_k,
check_installed = TRUE,
bootstrap       = bootstrap,
bootstrap_N     = boostrap_number,
maxiter         = maxiter,
bootstrap_type  = parallel_type,
seed            = seed,
volume_ratio    = volume_ratio,
delta           = delta,
conv_crit       = conv_crit,
order_type      = order_type,
sample_prop     = sample_proportion)
message('--- Checking packages ---')
is_package_installed('ParetoTI')
is_package_installed('reticulate')
n_dimensions         = as.integer(n_dimensions)           # number of components
max_k                = as.integer(max_k)           # maximum k number
maxiter              = as.integer(maxiter)         # maximum number of iterations to find the archetypes in a given run
boostrap_number      = as.integer(boostrap_number) # number of trial via bootstrap
delta                = as.integer(delta)
conv_crit            = as.double(conv_crit)        # convergence threshold
seed                 = as.integer(seed)
# setting the range of archetypes to test on the data
if(is.null(interval_of_k)) interval_of_k <- seq(2, max_k)
## ADD ALSO ICA!
sce <- switch(reduction_method,
'pca' = decomp_pca(sce,
n_dimensions,
assay = assay,
result_name = reduction_method),
'nmf' = decomp_nmf(sce,
n_dimensions,
assay = assay,
result_name = reduction_method),
'none' = sce)
if(reduction_method == 'none'){
reduced_matrix <- assay(sce, assay)
}else{
# we need to transpose the matrix to have it features x cells
reduced_matrix <- t(reducedDims(sce)[[reduction_method]])}
source("~/Documents/ruler/R/decomp_pca.R", echo=TRUE)
## ADD ALSO ICA!
sce <- switch(reduction_method,
'pca' = decomp_pca(sce,
n_dimensions,
assay = assay,
result_name = reduction_method),
'nmf' = decomp_nmf(sce,
n_dimensions,
assay = assay,
result_name = reduction_method),
'none' = sce)
source("~/Documents/ruler/R/decomp_pca.R", echo=TRUE)
is_python_package_installed(packages.vec = 'scikit-learn',
envname = envname)
is_python_package_installed
is_package_installed('reticulate')
is_python_package_installed(packages.vec = 'scikit-learn',
envname = envname)
envname='r-decomp'
is_python_package_installed(packages.vec = 'scikit-learn',
envname = envname)
reticulate::use_virtualenv(envname)
envname='r-decomp'
is_python_package_installed(envname = envname, packages.vec = c('nimfa'))
reticulate::use_virtualenv(envname)
is_package_installed('ParetoTI')
is_package_installed('reticulate')
ParetoTI::install_py_pcha
is_python_package_installed(envname = 'r-decomp',
packages.vec = c('py_pcha',
'datetime',
'scipy',
'numpy'))
sce
n_dimensions         = as.integer(n_dimensions)           # number of components
sce
n_dimensions=50         # number of dimensions for the compressed representation
reduction_method='pca'# dimensionality reduction method
assay='counts'       # assay to be reduced in dimensions
max_k=16                # maximum k number
maxiter=50              # maximum number of iterations to find the archetypes in a given run
boostrap_number=10      #
delta=0                 #
conv_crit=1e-04         #
seed=42                 #
bootstrap=TRUE          # whether to perform bootstrap for more robust results
parallel_type='m'       # to run locally or on a single node
volume_ratio='t_ratio'  # use none for quicker and less precise computations
order_type="align"      #
sample_proportion=NULL  # 0.25 | with NULL it runs multiple times on the whole data set, to evaluate local optima.
interval_of_k=NULL
compressed_representation=NULL
message('--- Checking packages ---')
is_package_installed('ParetoTI')
is_package_installed('reticulate')
is_python_package_installed(envname = 'r-decomp',
packages.vec = c('py_pcha', 'datetime',
'scipy', 'numpy'))
reticulate::use_virtualenv(envname)
n_dimensions         = as.integer(n_dimensions)           # number of components
max_k                = as.integer(max_k)           # maximum k number
maxiter              = as.integer(maxiter)         # maximum number of iterations to find the archetypes in a given run
boostrap_number      = as.integer(boostrap_number) # number of trial via bootstrap
delta                = as.integer(delta)
conv_crit            = as.double(conv_crit)        # convergence threshold
seed                 = as.integer(seed)
# setting the range of archetypes to test on the data
if(is.null(interval_of_k)) interval_of_k <- seq(2, max_k)
## ADD ALSO ICA!
sce <- switch(reduction_method,
'pca' = decomp_pca(sce,
n_dimensions,
assay = assay,
result_name = reduction_method),
'nmf' = decomp_nmf(sce,
n_dimensions,
assay = assay,
result_name = reduction_method),
'none' = sce)
