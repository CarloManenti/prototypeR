% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/decomp_va.R
\name{decomp_va}
\alias{decomp_va}
\title{Non Linear Decomposition Approach : Variational AutoEncoder (VAE)}
\usage{
decomp_va(
  sce,
  n_components,
  max_epochs = 400,
  n_highly_variable_genes = 5000,
  assay = "counts",
  categorical_covariate_keys = c(),
  continuous_covariate_keys = c(),
  target_sum = NULL,
  accelerator = "cpu",
  ignore_warnings = TRUE,
  result_name = "va",
  envname = "r-decomp",
  return_model = FALSE,
  seed = 42,
  verbose = FALSE,
  ...
)
}
\arguments{
\item{sce}{<SingleCellExperiment object> SCE object}

\item{n_components}{<integer> number of latents (VAE) desired.}

\item{max_epochs}{<integer> default 400; Number of epochs to fit the VAE.
The higher the number of epochs, the better (hopefully) the results.
note : it is not always the case given that we are working with Neural
Networks. A very naive approach would be to fit the model with a moderate
number of epochs and try increasing the number later on…}

\item{n_highly_variable_genes}{<integer> default 5000; number of Highly
Variable Genes to be selected for downstream analysis and fitting the
VAE.}

\item{assay}{<character> default 'counts'; Assay storing the raw counts.}

\item{categorical_covariate_keys}{< vector of characters or NULL> default
NULL; states the fields of categorical covariates to correct for.}

\item{continuous_covariate_keys}{< vector of characters or NULL> default
NULL; states the fields of continuous covariates to correct for.}

\item{target_sum}{<integer or NULL> default NULL; target sum used to
normalize the raw counts. If NULL it uses the mean of all the cells in the
raw count matrix. Otherwise is generally set to 1e4.}

\item{accelerator}{<character> default 'cpu'. Type of accelerations to be
used to fit the model. It can be one of :
*cpu* : Central Processing Unit (CPU), vanilla use of the CPU's processors.
*gpu* : Graphics Processing Unit (GPU), preferable acceleration when
note: gpu acceleration, due to inherent variability in GPU processing of data
available will introduce slight differences every time is run, thus making
the process less reproducible, but much faster!
Other types of acceleration are *tpu*, *ipu*, *hpu*, *mps*, *auto*
as well as custom accelerator instances.
note: Only *cpu* is available for MAC ARCH architectures, for now (2024)}

\item{ignore_warnings}{<bool> default FALSE; Whether to avoid warnings.
note: using verbose = FALSE and ignore warnings = TRUE may result in
the suppression of warnings due to suppressing most of the messages from
the function.}

\item{result_name}{<character> default 'va';
Name used to store the result in the SingleCellExperiment object.}

\item{envname}{<character> default 'r-decomp';
Specify the name of the python virtual
environment to be used. If it does not exists it will create one and use it.}

\item{return_model}{<bool> default FALSE; Whether to return also
the model and not only
the SingleCellExperiment object.}

\item{seed}{<integer> default 42; to set the seed for reproducibility.}

\item{verbose}{<bool> default FALSE; Whether to be prompted with message
for each step of the analysis.}

\item{...}{<extra parameters for the function train>}
}
\value{
either a SingleCellExperiment object with both H and W
representations or the SingleCellExperiment object and the model
used to perform X
}
\description{
This function performs non linear decomposition leveraging a Variational
AutoEncoder. It stores the results directly inside the SingleCellExperiment
(SCE) input object. Also It tries to leverage acceleration (GPU, or others…)
if it is available. note: on Mac ARM architectures it will fail to use 'gpu'
acceleration even if it is available and is detected!
}
\examples{
#decomp_va(sce, n_components = 5, accelerator = 'cpu', verbose = TRUE, max_epochs = 10)
}
